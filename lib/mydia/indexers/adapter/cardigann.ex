defmodule Mydia.Indexers.Adapter.Cardigann do
  @moduledoc """
  Cardigann indexer adapter for native Prowlarr/Cardigann definition support.

  This adapter integrates Cardigann search engine with the existing Indexers
  module, allowing direct execution of searches using Cardigann YAML definitions
  without requiring external Prowlarr or Jackett instances.

  ## Configuration

  The adapter expects a config map with the following structure:

      %{
        type: :cardigann,
        name: "Indexer Name",
        indexer_id: "1337x",
        enabled: true,
        user_settings: %{
          # User-provided credentials if needed for private indexers
          username: "user",
          password: "pass",
          # Or API key
          api_key: "..."
        }
      }

  ## Example Usage

      config = %{
        type: :cardigann,
        name: "1337x",
        indexer_id: "1337x",
        enabled: true
      }

      {:ok, results} = Cardigann.search(config, "Ubuntu 22.04")

  ## Integration

  - Fetches definition from database using `indexer_id`
  - Parses definition using `CardigannParser`
  - Executes search using `CardigannSearchEngine`
  - Parses results using `CardigannResultParser`
  - Returns normalized `SearchResult` structs

  ## Authentication

  For private indexers requiring authentication:
  - Credentials stored in `user_settings` map
  - Login handled by `CardigannSearchSession` (future implementation)
  - Cookies managed per-user, per-indexer
  """

  @behaviour Mydia.Indexers.Adapter

  alias Mydia.Indexers.{CardigannParser, CardigannSearchEngine, CardigannResultParser}
  alias Mydia.Indexers.{CardigannDefinition, CardigannAuth, CardigannFeatureFlags}
  alias Mydia.Indexers.CardigannSearchSession
  alias Mydia.Indexers.Adapter.Error
  alias Mydia.Repo

  import Ecto.Query

  require Logger

  @impl true
  def test_connection(config) do
    if CardigannFeatureFlags.enabled?() do
      with {:ok, definition} <- fetch_definition(config),
           {:ok, parsed} <- parse_definition(definition),
           :ok <- test_indexer_reachable(parsed, config) do
        {:ok,
         %{
           name: parsed.name,
           type: parsed.type,
           language: parsed.language,
           indexer_id: parsed.id
         }}
      end
    else
      Logger.debug("Cardigann test connection skipped - feature disabled")
      {:error, Error.invalid_config("Cardigann feature is disabled")}
    end
  end

  @impl true
  def search(config, query, opts \\ []) do
    if CardigannFeatureFlags.enabled?() do
      with {:ok, definition} <- fetch_definition(config),
           {:ok, parsed} <- parse_definition(definition),
           {:ok, search_opts} <- build_search_opts(parsed, definition, query, opts),
           {:ok, user_config} <- get_or_create_session(parsed, definition, config),
           flaresolverr_opts <- build_flaresolverr_opts(definition),
           {:ok, response, flaresolverr_result} <-
             execute_search_with_flaresolverr(
               parsed,
               search_opts,
               user_config,
               flaresolverr_opts,
               definition
             ) do
        # Build template context for filter rendering
        template_context = build_template_context_for_parsing(parsed, user_config, search_opts)

        # Parse results with template context
        with {:ok, results} <-
               CardigannResultParser.parse_results(parsed, response, config.name,
                 template_context: template_context
               ) do
          # Handle FlareSolverr result (store cookies, update flags)
          handle_flaresolverr_result(definition, flaresolverr_result)

          # Apply filters from opts if present
          filtered_results = apply_search_filters(results, opts)
          {:ok, filtered_results}
        end
      else
        {:error, %Error{} = error} ->
          {:error, error}

        {:error, reason} ->
          Logger.error("Cardigann search failed: #{inspect(reason)}")
          {:error, Error.search_failed("Search failed: #{inspect(reason)}")}
      end
    else
      Logger.debug("Cardigann search skipped - feature disabled")
      {:ok, []}
    end
  end

  # Execute search and normalize the result to always include flaresolverr_result
  defp execute_search_with_flaresolverr(
         parsed,
         search_opts,
         user_config,
         flaresolverr_opts,
         definition
       ) do
    # Merge FlareSolverr cookies into user_config if available
    user_config_with_fs_cookies = maybe_add_flaresolverr_cookies(user_config, definition)

    case CardigannSearchEngine.execute_search(
           parsed,
           search_opts,
           user_config_with_fs_cookies,
           flaresolverr_opts
         ) do
      {:ok, response, cookies} ->
        {:ok, response, {:flaresolverr_cookies, cookies}}

      {:ok, response} ->
        {:ok, response, :no_flaresolverr}

      {:error, _} = error ->
        error
    end
  end

  # Add FlareSolverr cookies from stored session if available
  defp maybe_add_flaresolverr_cookies(user_config, definition) do
    case get_flaresolverr_session(definition.id) do
      {:ok, session} ->
        # Merge cookies with existing user_config cookies
        existing_cookies = Map.get(user_config, :cookies, [])

        # session.cookies should be a list of cookie maps
        # Handle different formats defensively
        fs_cookies =
          session.cookies
          |> normalize_cookies()
          |> Enum.flat_map(fn
            cookie when is_map(cookie) ->
              name = cookie["name"] || Map.get(cookie, :name)
              value = cookie["value"] || Map.get(cookie, :value)

              if name && value do
                ["#{name}=#{value}"]
              else
                []
              end

            _ ->
              []
          end)

        Map.put(user_config, :cookies, existing_cookies ++ fs_cookies)

      {:error, _} ->
        user_config
    end
  end

  # Normalize cookies from various storage formats to a list of maps
  # Handles: list of maps, map with numeric keys, map with "cookies" key, etc.
  defp normalize_cookies(cookies) when is_list(cookies), do: cookies

  defp normalize_cookies(%{"cookies" => cookies}) when is_list(cookies), do: cookies

  defp normalize_cookies(cookies) when is_map(cookies) do
    # If map values are cookie maps (have "name" key), extract them
    values = Map.values(cookies)

    case values do
      [first | _] when is_map(first) and is_map_key(first, "name") ->
        values

      [first | _] when is_list(first) ->
        # Nested list - flatten one level
        List.flatten(values)

      _ ->
        []
    end
  end

  defp normalize_cookies(_), do: []

  # Build FlareSolverr options from definition
  defp build_flaresolverr_opts(%CardigannDefinition{} = definition) do
    %{
      enabled: CardigannDefinition.use_flaresolverr?(definition),
      definition_id: definition.id
    }
  end

  # Handle FlareSolverr result - store cookies and update flags
  defp handle_flaresolverr_result(definition, {:flaresolverr_cookies, cookies}) do
    # Check if FlareSolverr was auto-detected as required
    flaresolverr_required =
      Enum.find(cookies, fn
        {:flaresolverr_required, true} -> true
        _ -> false
      end)

    # Extract actual cookies (filter out metadata)
    actual_cookies =
      Enum.reject(cookies, fn
        {:flaresolverr_required, _} -> true
        _ -> false
      end)

    # Update definition if FlareSolverr was auto-detected
    if flaresolverr_required do
      mark_flaresolverr_required(definition)
    end

    # Store cookies for future requests
    if actual_cookies != [] do
      store_flaresolverr_cookies(definition, actual_cookies)
    end

    :ok
  end

  defp handle_flaresolverr_result(_definition, :no_flaresolverr), do: :ok

  # Mark an indexer as requiring FlareSolverr
  defp mark_flaresolverr_required(%CardigannDefinition{flaresolverr_required: true}), do: :ok

  defp mark_flaresolverr_required(%CardigannDefinition{} = definition) do
    Logger.info("Auto-detected FlareSolverr requirement for indexer: #{definition.indexer_id}")

    definition
    |> CardigannDefinition.flaresolverr_changeset(%{
      flaresolverr_required: true,
      flaresolverr_enabled: true
    })
    |> Repo.update()
    |> case do
      {:ok, _} ->
        Logger.debug("Updated indexer #{definition.indexer_id} FlareSolverr settings")

      {:error, changeset} ->
        Logger.error("Failed to update FlareSolverr settings: #{inspect(changeset.errors)}")
    end
  end

  # Store FlareSolverr cookies in the database
  defp store_flaresolverr_cookies(%CardigannDefinition{} = definition, cookies) do
    # Convert cookies to JSON-serializable format
    cookie_data =
      Enum.map(cookies, fn cookie ->
        %{
          "name" => cookie.name,
          "value" => cookie.value,
          "domain" => cookie.domain,
          "path" => cookie.path || "/",
          "expires" => cookie.expires,
          "secure" => cookie.secure || false,
          "httpOnly" => cookie.http_only || false
        }
      end)

    # Calculate expiration from cookies (use earliest expiration, default 1 hour)
    expires_at = calculate_cookie_expiration(cookies)

    # Upsert the session
    case get_flaresolverr_session(definition.id) do
      {:ok, session} ->
        # Update existing session
        session
        |> CardigannSearchSession.changeset(%{
          cookies: cookie_data,
          expires_at: expires_at
        })
        |> Repo.update()

      {:error, :not_found} ->
        # Create new session
        %CardigannSearchSession{}
        |> CardigannSearchSession.changeset(%{
          cardigann_definition_id: definition.id,
          cookies: cookie_data,
          expires_at: expires_at
        })
        |> Repo.insert()
    end
    |> case do
      {:ok, _} ->
        Logger.debug(
          "Stored #{length(cookies)} FlareSolverr cookies for #{definition.indexer_id}"
        )

      {:error, changeset} ->
        Logger.error("Failed to store FlareSolverr cookies: #{inspect(changeset.errors)}")
    end
  end

  # Calculate expiration time from cookies
  defp calculate_cookie_expiration(cookies) do
    # Find the earliest expiration time from cookies
    min_expiration =
      cookies
      |> Enum.map(fn cookie -> cookie.expires end)
      |> Enum.reject(&is_nil/1)
      |> Enum.min(fn -> nil end)

    case min_expiration do
      nil ->
        # Default to 1 hour if no expiration set
        DateTime.utc_now() |> DateTime.add(3600, :second) |> DateTime.truncate(:second)

      timestamp when is_number(timestamp) ->
        # Convert Unix timestamp to DateTime
        DateTime.from_unix!(trunc(timestamp)) |> DateTime.truncate(:second)
    end
  end

  # Get stored FlareSolverr session
  defp get_flaresolverr_session(definition_id) do
    query =
      from s in CardigannSearchSession,
        where: s.cardigann_definition_id == ^definition_id,
        order_by: [desc: s.updated_at],
        limit: 1

    case Repo.one(query) do
      nil ->
        {:error, :not_found}

      session ->
        # Check if session is expired
        if CardigannSearchSession.expired?(session) do
          # Delete expired session
          Repo.delete(session)
          {:error, :expired}
        else
          {:ok, session}
        end
    end
  end

  @impl true
  def get_capabilities(config) do
    with {:ok, definition} <- fetch_definition(config),
         {:ok, parsed} <- parse_definition(definition) do
      capabilities = build_capabilities_response(parsed)
      {:ok, capabilities}
    end
  end

  ## Private Functions

  defp fetch_definition(%{indexer_id: indexer_id}) do
    case Repo.get_by(CardigannDefinition, indexer_id: indexer_id) do
      nil ->
        {:error, Error.invalid_config("Cardigann definition not found: #{indexer_id}")}

      definition ->
        {:ok, definition}
    end
  end

  defp fetch_definition(_config) do
    {:error, Error.invalid_config("Missing indexer_id in config")}
  end

  defp parse_definition(%CardigannDefinition{definition: yaml_string}) do
    case CardigannParser.parse_definition(yaml_string) do
      {:ok, parsed} ->
        {:ok, parsed}

      {:error, reason} ->
        Logger.error("Failed to parse Cardigann definition: #{inspect(reason)}")
        {:error, Error.search_failed("Invalid definition: #{inspect(reason)}")}
    end
  end

  defp test_indexer_reachable(parsed, _config) do
    # Build a simple test URL to check if the indexer is reachable
    case parsed.links do
      [base_url | _] ->
        # Try to fetch the base URL to verify connectivity
        case Req.get(base_url, receive_timeout: 10_000, redirect: false) do
          {:ok, %Req.Response{status: status}} when status in 200..399 ->
            :ok

          {:ok, %Req.Response{status: status}} ->
            Logger.warning("Indexer returned HTTP #{status}, but may still be functional")
            :ok

          {:error, %Mint.TransportError{reason: reason}} ->
            {:error, Error.connection_failed("Connection failed: #{inspect(reason)}")}

          {:error, reason} ->
            {:error, Error.connection_failed("Request failed: #{inspect(reason)}")}
        end

      [] ->
        {:error, Error.invalid_config("No base URL configured in definition")}
    end
  end

  defp build_search_opts(parsed, definition, query, opts) do
    search_opts = [
      query: query,
      categories: Keyword.get(opts, :categories, []),
      season: Keyword.get(opts, :season),
      episode: Keyword.get(opts, :episode),
      imdb_id: Keyword.get(opts, :imdb_id),
      tmdb_id: Keyword.get(opts, :tmdb_id),
      config: definition.config || %{},
      settings: parsed.settings
    ]

    {:ok, search_opts}
  end

  defp get_or_create_session(parsed, definition, config) do
    user_settings = Map.get(config, :user_settings, %{})

    # Build user config from settings
    credentials = %{
      username: Map.get(user_settings, :username),
      password: Map.get(user_settings, :password),
      api_key: Map.get(user_settings, :api_key),
      cookies: Map.get(user_settings, :cookies, [])
    }

    # Remove nil values
    credentials = Map.reject(credentials, fn {_k, v} -> is_nil(v) end)

    # Try to get stored session first
    case CardigannAuth.get_stored_session(definition.id) do
      {:ok, session} ->
        # Validate session hasn't expired
        if CardigannAuth.validate_session(session, parsed) do
          {:ok, convert_session_to_user_config(session)}
        else
          # Session expired, re-authenticate
          authenticate_and_convert(parsed, credentials, definition.id)
        end

      {:error, :not_found} ->
        # No stored session, authenticate if needed
        authenticate_and_convert(parsed, credentials, definition.id)

      {:error, :expired} ->
        # Session expired, re-authenticate
        authenticate_and_convert(parsed, credentials, definition.id)
    end
  end

  defp authenticate_and_convert(parsed, credentials, definition_id) do
    case CardigannAuth.authenticate(parsed, credentials, definition_id) do
      {:ok, session} ->
        {:ok, convert_session_to_user_config(session)}

      {:error, error} ->
        # If authentication is required but failed, return error
        # Otherwise return empty config for public indexers
        if parsed.login != nil and credentials != %{} do
          {:error, error}
        else
          {:ok, %{}}
        end
    end
  end

  defp convert_session_to_user_config(session) do
    case session.method do
      :api_key ->
        %{api_key: session.api_key}

      :cookie ->
        %{cookies: session.cookies}

      :form ->
        %{cookies: session.cookies}

      :none ->
        %{}
    end
  end

  defp apply_search_filters(results, opts) do
    results
    |> filter_by_min_seeders(Keyword.get(opts, :min_seeders, 0))
    |> filter_by_min_size(Keyword.get(opts, :min_size))
    |> filter_by_max_size(Keyword.get(opts, :max_size))
    |> limit_results(Keyword.get(opts, :limit))
  end

  defp filter_by_min_seeders(results, min_seeders) when min_seeders > 0 do
    Enum.filter(results, fn result -> result.seeders >= min_seeders end)
  end

  defp filter_by_min_seeders(results, _), do: results

  defp filter_by_min_size(results, nil), do: results

  defp filter_by_min_size(results, min_size) do
    Enum.filter(results, fn result -> result.size >= min_size end)
  end

  defp filter_by_max_size(results, nil), do: results

  defp filter_by_max_size(results, max_size) do
    Enum.filter(results, fn result -> result.size <= max_size end)
  end

  defp limit_results(results, nil), do: results
  defp limit_results(results, limit), do: Enum.take(results, limit)

  defp build_capabilities_response(parsed) do
    # Extract categories from the definition
    categories = extract_categories(parsed.capabilities)

    # Build capabilities map compatible with Adapter behaviour
    %{
      searching: %{
        search: %{available: true, supported_params: ["q"]},
        tv_search: %{
          available: has_tv_search_mode?(parsed),
          supported_params: ["q", "season", "ep"]
        },
        movie_search: %{
          available: has_movie_search_mode?(parsed),
          supported_params: ["q", "imdbid", "tmdbid"]
        }
      },
      categories: categories
    }
  end

  defp extract_categories(%{categorymappings: mappings}) when is_list(mappings) do
    Enum.map(mappings, fn mapping ->
      %{
        id: Map.get(mapping, "id"),
        name: Map.get(mapping, "name") || Map.get(mapping, "desc", "Unknown")
      }
    end)
    |> Enum.filter(fn cat -> cat.id != nil end)
  end

  defp extract_categories(_), do: []

  defp has_tv_search_mode?(%{capabilities: %{modes: modes}}) when is_map(modes) do
    Map.has_key?(modes, "tv-search") || Map.has_key?(modes, "tvsearch")
  end

  defp has_tv_search_mode?(_), do: false

  defp has_movie_search_mode?(%{capabilities: %{modes: modes}}) when is_map(modes) do
    Map.has_key?(modes, "movie-search") || Map.has_key?(modes, "moviesearch")
  end

  defp has_movie_search_mode?(_), do: false

  # Build template context for rendering filter arguments during result parsing
  defp build_template_context_for_parsing(parsed, user_config, search_opts) do
    # Extract user configuration settings
    config_map =
      case user_config do
        %{config: config} when is_map(config) -> config
        %{"config" => config} when is_map(config) -> config
        _ -> %{}
      end

    # Extract query from search_opts
    query = Keyword.get(search_opts, :query, "")

    # Build context similar to search engine template context
    %{
      keywords: query,
      config: config_map,
      query: %{},
      categories: [],
      settings: parsed.settings || []
    }
  end
end
